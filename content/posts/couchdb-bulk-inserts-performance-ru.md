Title: CouchDB bulk insert's performance
Slug: couchdb-bulk-inserts-performance
Date: 2008-11-19 03:24
Tags: couchdb, database, scalability
Category: texts
Lang: ru
Description: Тест на производительность CouchDB при массовых вставках.

Несколько дней назад, я обнаружил две статьи [Демиена Катза][Katz] и [Яна Ленхарда][Jan] про масштабируемость [CouchDB's][couchdb], и решил написать свой собственный тест.

Мой тест очень похож на тест Яна Ленхарда, но написан на языке Python. Он использует почти такую же структуру данных, но главная цель моего теста - проверка масштабируемости [CouchDB's][couchdb] на больших объемах данных.

Я измерил RPS — количество записей в секунду и сделал три теста.

Потоки
======

Первый, проевряет, как производительность зависит от количества одновременных подключений. Здесь, я вставляю по 100 записей за раз, и так до 100000. Число потоков изменяется от 2 до 16. Вот результат этого теста. График показывает, как зависит RPS от размера базы данных и числа потоков:

<inline type="media.photo" id="3" class="center" />

Как видно, значения почти одинаковы для всех параметров. Очевидно, что-то неправильно в моей тестовой среде.

Размер пачки
============

Далее, я попытался определить, как RPS зависит от объема одновременно записываемых данных. На следующем графике можно увидеть, как CouchDB работает с бачками от 10 до 10000 записей:

<inline type="media.photo" id="2" class="center" />

Самую высокую производительность показывают массовые вставки 10000 записей одновременно. И при большом размере базы данных, RPS стремится к уровню, который зависит от размера пачки. Как вы можете видеть, 10000 дает лучшую производительность. Это около 1250 строк в секунду при объеме базы данных в 100000 документов.

Размер базы данных
=========

Мой последний тест больше похож на стресс-тест, чем тест на производительности, потому что я попытался создать большую базу данных с 4 млн. документов и посмотреть, как RPS зависит от размера базы данных. Вот получившаяся картинка:

<inline type="media.photo" id="4" class="center" />

Окончательный размер базы данных 9,5G. И CouchDB падал в несколько раз, когда размер базы данных достигал границы 5.6G. Я не знаю причины этих падений, но у меня есть `erl_crash.dump` и `couchdb.log` с ошибками.

Надо признать, что CouchDB работает довольно нестабильно после 2,5 миллионов записей в базе данных. Обратите внимание на эти красные пики на диаграмме. Я думаю, что это реальные ограничения на размер данных.

Все эти испытания работали на моем ноутбуке с 1G ОЗУ и процессором Intel Centrino Duo. Я смотрел на `dstat` и `top` во время тестов и заметил, что первые два теста упираются в CPU, а последний - в операции ввода-вывода из-за нехватки оперативной памяти.

Во всяком случае, здесь источник кода моего теста [test-code]. Вы можете запустить его на собственном оборудовании и поделиться результатами с общественностью. Более того, вы можете улучшить тесты и добавить, например, тест на выборку или что-то подобное. Я думаю, будет очень интересно посмотреть на скорость выборки.

[katz]: http://damienkatz.net/2007/12/couchdb_perform_1.html
[jan]: http://userprimary.net/user/2007/12/16/a-quick-look-at-couchdb-performance/
[couchdb]: http://couchdb.org/
[test-code]: http://github.com/svetlyak40wt/couchdb-performance-tests/
